{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ilya-talankin/LSTM-power-forecasting/blob/main/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFrLAjaTyyGe"
      },
      "source": [
        "Функция для трансормации таблицы с данными в подходящую для LSTM размерность\n",
        "\n",
        "(кол-во измерений, кол-во временных шагов, кол-во параметров) т. е. -> (n, historyInterval, 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUzAIfj37arY"
      },
      "outputs": [],
      "source": [
        "def prepareData(dataCsv, historyInterval):\n",
        "    x = []\n",
        "    y = []\n",
        "    power = dataCsv.pop('power_normed')\n",
        "    power = np.array(power)\n",
        "    features = np.array(dataCsv)\n",
        "    for i in range(historyInterval, len(features) - historyInterval):\n",
        "        x.append(features[i - historyInterval : i])\n",
        "        y.append(sum(power[i : i + 5]))\n",
        "    return np.array(x), np.array(y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJA8l2ZI1nWv"
      },
      "source": [
        "Функция для разделения данных на тестовые, тренировочные и валидационные.\n",
        "\n",
        "test_ratio - какая часть данных будет использована для тестирования"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_Y_f3SMvISw"
      },
      "outputs": [],
      "source": [
        "from collections import namedtuple\n",
        "Splitted = namedtuple(\"Splitted\", [\"test\", \"train\", \"val\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysu2uBYZ46AU"
      },
      "outputs": [],
      "source": [
        "def splitData(x, y, test_ratio = 0.8):\n",
        "\n",
        "    test_idx = int(test_ratio * x.shape[0])\n",
        "    x_test = x[test_idx:]\n",
        "    y_test = y[test_idx:]\n",
        "    x_train, x_val, y_train, y_val = train_test_split(x[:test_idx], y[:test_idx], test_size=0.1, shuffle=False)\n",
        "\n",
        "    return Splitted(x_test, x_train, x_val), Splitted(y_test, y_train, y_val)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILExLuTD1XAi"
      },
      "source": [
        "0. Необходимые модули"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKoZa2I21CFD"
      },
      "outputs": [],
      "source": [
        "# includes\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "from keras import optimizers\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TAb6BMC1PLR"
      },
      "source": [
        "1. Загрузка данных с гугл диска"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhslRsMhpWah"
      },
      "outputs": [],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# read data\n",
        "os.chdir('/content/drive/MyDrive/Solar-Power-Forecasting/GermanSolarFarm/data/')\n",
        "csv_files_list = [f for f in os.listdir('.') if f.endswith('.csv')]\n",
        "all_stations_data = []\n",
        "for csv_file_name in csv_files_list:\n",
        "    station_data = pd.read_csv(csv_file_name, delimiter=';')\n",
        "    station_data = station_data.drop('Unnamed: 51', axis=1)\n",
        "    all_stations_data.append(station_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7la9foSZ4B8q"
      },
      "source": [
        "2. Создание модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CM7vIxpB8Cu"
      },
      "outputs": [],
      "source": [
        "historyInterval = 10 # данные каждые 3 часа -> 16 * 3 = 48 часов\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, activation='relu', input_shape=(historyInterval, 50), return_sequences=True))\n",
        "model.add(LSTM(64, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mse', optimizer=optimizers.Adam(learning_rate=1e-4), metrics=['mae'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXLmOs716g2n"
      },
      "source": [
        "3. Обучение"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                              patience=1, min_lr=0.001)"
      ],
      "metadata": {
        "id": "Z0O3ASbmoczj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HksJGW5YD8fY"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "history = dict({'loss': [], 'mae': [], 'val_loss': [], 'val_mae': []})\n",
        "for i in range(0, 50):\n",
        "    print('Epoch number ', i)\n",
        "    random.shuffle(all_stations_data);\n",
        "    for station_data in all_stations_data:\n",
        "        x, y = prepareData(station_data.copy(), historyInterval)\n",
        "        x, y = splitData(x, y)\n",
        "        model.fit(x.train, y.train, epochs=1, validation_data=(x.val, y.val), callbacks=[reduce_lr])\n",
        "        history['loss'].append(model.history.history['loss'])\n",
        "        history['mae'].append(model.history.history['mae'])\n",
        "        history['val_loss'].append(model.history.history['val_loss'])\n",
        "        history['val_mae'].append(model.history.history['val_mae'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSNGR1KlUcA4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get the training history\n",
        "history = model.history.history\n",
        "\n",
        "# Plot the training and validation loss over time\n",
        "plt.plot(history['loss'])\n",
        "plt.plot(history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylim(0,1)\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "# Plot the training and validation accuracy over time\n",
        "plt.plot(history['mae'])\n",
        "plt.plot(history['val_mae'])\n",
        "plt.title('Model mae')\n",
        "plt.ylabel('Mae')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xSY1YPiCxp-"
      },
      "outputs": [],
      "source": [
        "history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pw9uAAAjHphG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPBJPg+rQWbDctDHFr11Neb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}